{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IHhfsd7IY1Z",
        "outputId": "0f5396e5-2227-4ddb-83ab-adb095a01b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Employee Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|Employee Name|Department|Salary|\n",
            "+-------------+----------+------+\n",
            "|James        |Sales     |3000  |\n",
            "|Michael      |Sales     |4600  |\n",
            "|Robert       |Sales     |4100  |\n",
            "|Maria        |Finance   |3000  |\n",
            "|James        |Sales     |3000  |\n",
            "|Scott        |Finance   |3300  |\n",
            "|Jen          |Finance   |3900  |\n",
            "|Jeff         |Marketing |3000  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Saif         |Sales     |4100  |\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"PySpark Window Functions\").getOrCreate()\n",
        "\n",
        "simpleData = ((\"James\", \"Sales\", 3000), \\\n",
        "    (\"Michael\", \"Sales\", 4600),  \\\n",
        "    (\"Robert\", \"Sales\", 4100),   \\\n",
        "    (\"Maria\", \"Finance\", 3000),  \\\n",
        "    (\"James\", \"Sales\", 3000),    \\\n",
        "    (\"Scott\", \"Finance\", 3300),  \\\n",
        "    (\"Jen\", \"Finance\", 3900),    \\\n",
        "    (\"Jeff\", \"Marketing\", 3000), \\\n",
        "    (\"Kumar\", \"Marketing\", 2000),\\\n",
        "    (\"Saif\", \"Sales\", 4100) \\\n",
        "  )\n",
        "\n",
        "columns = [\"Employee Name\", \"Department\", \"Salary\"]\n",
        "\n",
        "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
        "df.printSchema()\n",
        "df.show(truncate = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Row Number\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "windowSpec = Window.partitionBy(\"Department\").orderBy(\"Salary\")\n",
        "\n",
        "df.withColumn(\"row_number\",row_number().over(windowSpec))\\\n",
        ".show(truncate = False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIc00Uy-JiF8",
        "outputId": "8543fa4d-1732-4f33-ddd1-9b8b6cb0cca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----------+\n",
            "|Employee Name|Department|Salary|row_number|\n",
            "+-------------+----------+------+----------+\n",
            "|Maria        |Finance   |3000  |1         |\n",
            "|Scott        |Finance   |3300  |2         |\n",
            "|Jen          |Finance   |3900  |3         |\n",
            "|Kumar        |Marketing |2000  |1         |\n",
            "|Jeff         |Marketing |3000  |2         |\n",
            "|James        |Sales     |3000  |1         |\n",
            "|James        |Sales     |3000  |2         |\n",
            "|Robert       |Sales     |4100  |3         |\n",
            "|Saif         |Sales     |4100  |4         |\n",
            "|Michael      |Sales     |4600  |5         |\n",
            "+-------------+----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rank\n",
        "from pyspark.sql.functions import rank\n",
        "df.withColumn(\"rank\", rank().over(windowSpec))\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te5PMkS7KBoI",
        "outputId": "08a64f84-5759-4525-c348-0c8264876730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----+\n",
            "|Employee Name|Department|Salary|rank|\n",
            "+-------------+----------+------+----+\n",
            "|        Maria|   Finance|  3000|   1|\n",
            "|        Scott|   Finance|  3300|   2|\n",
            "|          Jen|   Finance|  3900|   3|\n",
            "|        Kumar| Marketing|  2000|   1|\n",
            "|         Jeff| Marketing|  3000|   2|\n",
            "|        James|     Sales|  3000|   1|\n",
            "|        James|     Sales|  3000|   1|\n",
            "|       Robert|     Sales|  4100|   3|\n",
            "|         Saif|     Sales|  4100|   3|\n",
            "|      Michael|     Sales|  4600|   5|\n",
            "+-------------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense Rank\n",
        "from pyspark.sql.functions import dense_rank\n",
        "df.withColumn(\"dense_rank\", dense_rank().over(windowSpec))\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpcAeszVKNyj",
        "outputId": "86fe8bb3-5cd1-46d9-a0a3-c016617f932d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----------+\n",
            "|Employee Name|Department|Salary|dense_rank|\n",
            "+-------------+----------+------+----------+\n",
            "|        Maria|   Finance|  3000|         1|\n",
            "|        Scott|   Finance|  3300|         2|\n",
            "|          Jen|   Finance|  3900|         3|\n",
            "|        Kumar| Marketing|  2000|         1|\n",
            "|         Jeff| Marketing|  3000|         2|\n",
            "|        James|     Sales|  3000|         1|\n",
            "|        James|     Sales|  3000|         1|\n",
            "|       Robert|     Sales|  4100|         2|\n",
            "|         Saif|     Sales|  4100|         2|\n",
            "|      Michael|     Sales|  4600|         3|\n",
            "+-------------+----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Percent Rank\n",
        "from pyspark.sql.functions import percent_rank\n",
        "df.withColumn(\"Percent Rank\", percent_rank().over(windowSpec))\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iTeuK9NKcIt",
        "outputId": "61055983-afdf-4095-95c8-79a76da9b353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+------------+\n",
            "|Employee Name|Department|Salary|Percent Rank|\n",
            "+-------------+----------+------+------------+\n",
            "|        Maria|   Finance|  3000|         0.0|\n",
            "|        Scott|   Finance|  3300|         0.5|\n",
            "|          Jen|   Finance|  3900|         1.0|\n",
            "|        Kumar| Marketing|  2000|         0.0|\n",
            "|         Jeff| Marketing|  3000|         1.0|\n",
            "|        James|     Sales|  3000|         0.0|\n",
            "|        James|     Sales|  3000|         0.0|\n",
            "|       Robert|     Sales|  4100|         0.5|\n",
            "|         Saif|     Sales|  4100|         0.5|\n",
            "|      Michael|     Sales|  4600|         1.0|\n",
            "+-------------+----------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ntile\n",
        "from pyspark.sql.functions import ntile\n",
        "df.withColumn(\"ntile\",ntile(2).over(windowSpec))\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XubyFJgjLHMw",
        "outputId": "a521aa42-7bfa-4fb9-89e2-604d8c23e264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+-----+\n",
            "|Employee Name|Department|Salary|ntile|\n",
            "+-------------+----------+------+-----+\n",
            "|        Maria|   Finance|  3000|    1|\n",
            "|        Scott|   Finance|  3300|    1|\n",
            "|          Jen|   Finance|  3900|    2|\n",
            "|        Kumar| Marketing|  2000|    1|\n",
            "|         Jeff| Marketing|  3000|    2|\n",
            "|        James|     Sales|  3000|    1|\n",
            "|        James|     Sales|  3000|    1|\n",
            "|       Robert|     Sales|  4100|    1|\n",
            "|         Saif|     Sales|  4100|    2|\n",
            "|      Michael|     Sales|  4600|    2|\n",
            "+-------------+----------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cume dist - CUmulative distribution\n",
        "from pyspark.sql.functions import cume_dist\n",
        "df.withColumn(\"cume_dist\", cume_dist().over(windowSpec))\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HftC3qELWVy",
        "outputId": "feb8b4f7-863f-4927-db95-3953db32f16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+------------------+\n",
            "|Employee Name|Department|Salary|         cume_dist|\n",
            "+-------------+----------+------+------------------+\n",
            "|        Maria|   Finance|  3000|0.3333333333333333|\n",
            "|        Scott|   Finance|  3300|0.6666666666666666|\n",
            "|          Jen|   Finance|  3900|               1.0|\n",
            "|        Kumar| Marketing|  2000|               0.5|\n",
            "|         Jeff| Marketing|  3000|               1.0|\n",
            "|        James|     Sales|  3000|               0.4|\n",
            "|        James|     Sales|  3000|               0.4|\n",
            "|       Robert|     Sales|  4100|               0.8|\n",
            "|         Saif|     Sales|  4100|               0.8|\n",
            "|      Michael|     Sales|  4600|               1.0|\n",
            "+-------------+----------+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lag\n",
        "from pyspark.sql.functions import lag\n",
        "df.withColumn(\"lag\", lag(\"salary\",2).over(windowSpec))\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5U3w8dLLtM-",
        "outputId": "0793642c-c48d-4048-86d2-ffaf1a89a8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----+\n",
            "|Employee Name|Department|Salary| lag|\n",
            "+-------------+----------+------+----+\n",
            "|        Maria|   Finance|  3000|NULL|\n",
            "|        Scott|   Finance|  3300|NULL|\n",
            "|          Jen|   Finance|  3900|3000|\n",
            "|        Kumar| Marketing|  2000|NULL|\n",
            "|         Jeff| Marketing|  3000|NULL|\n",
            "|        James|     Sales|  3000|NULL|\n",
            "|        James|     Sales|  3000|NULL|\n",
            "|       Robert|     Sales|  4100|3000|\n",
            "|         Saif|     Sales|  4100|3000|\n",
            "|      Michael|     Sales|  4600|4100|\n",
            "+-------------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lead\n",
        "from pyspark.sql.functions import lead\n",
        "df.withColumn(\"lead\", lead(\"salary\",2).over(windowSpec))\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL9xB-0vL9fO",
        "outputId": "390eb02c-2827-4adf-ca6f-4a9d9511e704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----+\n",
            "|Employee Name|Department|Salary|lead|\n",
            "+-------------+----------+------+----+\n",
            "|        Maria|   Finance|  3000|3900|\n",
            "|        Scott|   Finance|  3300|NULL|\n",
            "|          Jen|   Finance|  3900|NULL|\n",
            "|        Kumar| Marketing|  2000|NULL|\n",
            "|         Jeff| Marketing|  3000|NULL|\n",
            "|        James|     Sales|  3000|4100|\n",
            "|        James|     Sales|  3000|4100|\n",
            "|       Robert|     Sales|  4100|4600|\n",
            "|         Saif|     Sales|  4100|NULL|\n",
            "|      Michael|     Sales|  4600|NULL|\n",
            "+-------------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WindowsSpecAggregation\n",
        "\n",
        "windowSpecAgg = Window.partitionBy(\"Department\")\n",
        "from pyspark.sql.functions import col, avg, sum, min, max, row_number\n",
        "df.withColumn(\"Row\", row_number().over(windowSpec))\\\n",
        ".withColumn(\"Avg\", avg(col(\"Salary\")).over(windowSpec))\\\n",
        ".withColumn(\"Sum\", sum(col(\"Salary\")).over(windowSpec))\\\n",
        ".withColumn(\"Min\", min(col(\"Salary\")).over(windowSpec))\\\n",
        ".withColumn(\"Max\", max(col(\"Salary\")).over(windowSpec))\\\n",
        ".where(col(\"Row\") == 1).select(\"Department\", \"Avg\", \"Sum\", \"Min\", \"Max\")\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UAzyZezMIRC",
        "outputId": "334ed9d0-ff3a-42f5-bae4-3cea702215cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+----+----+----+\n",
            "|Department|   Avg| Sum| Min| Max|\n",
            "+----------+------+----+----+----+\n",
            "|   Finance|3000.0|3000|3000|3000|\n",
            "| Marketing|2000.0|2000|2000|2000|\n",
            "|     Sales|3000.0|6000|3000|3000|\n",
            "+----------+------+----+----+----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}