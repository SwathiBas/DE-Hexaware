{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEM72h8gn6x6",
        "outputId": "dc92e103-e7e3-4ff4-a479-f892270d0bba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+\n",
            "|     Name|Age|\n",
            "+---------+---+\n",
            "|   Swathi| 22|\n",
            "|    Chamm| 21|\n",
            "|     Amma| 51|\n",
            "|    Ekkoo| 27|\n",
            "|    James|  4|\n",
            "|Katherina| 16|\n",
            "+---------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "spark = SparkSession.builder.appName(\"PySpark Dataframe using external and rdd\").getOrCreate()\n",
        "\n",
        "df = spark.createDataFrame([(\"Swathi\",22), (\"Chamm\",21), (\"Amma\", 51), (\"Ekkoo\", 27), (\"James\", 4), (\"Katherina\", 16)], [\"Name\", \"Age\"])\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Col function and when function\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "df1 = df.withColumn(\"Stage_by_age\",\n",
        "                   when(col(\"Age\") < 13, \"Child\")\n",
        "                   .when(col(\"Age\").between(13, 19), \"Teenager\")\n",
        "                   .otherwise(\"Adult\"),\n",
        "                   )\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rydx77zwo93U",
        "outputId": "690e28fd-275c-49b5-82f3-cb0b9c82b33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+------------+\n",
            "|     Name|Age|Stage_by_age|\n",
            "+---------+---+------------+\n",
            "|   Swathi| 22|       Adult|\n",
            "|    Chamm| 21|       Adult|\n",
            "|     Amma| 51|       Adult|\n",
            "|    Ekkoo| 27|       Adult|\n",
            "|    James|  4|       Child|\n",
            "|Katherina| 16|    Teenager|\n",
            "+---------+---+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering Data\n",
        "df1.where(df1[\"Stage_by_age\"].isin([\"Teenager\", \"Child\"])).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF6V6xeeInTq",
        "outputId": "f1ee9eb2-427e-4c63-9c66-93ebde037ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+------------+\n",
            "|     Name|Age|Stage_by_age|\n",
            "+---------+---+------------+\n",
            "|    James|  4|       Child|\n",
            "|Katherina| 16|    Teenager|\n",
            "+---------+---+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group By Function\n",
        "df1.groupBy(\"Stage_by_age\").avg().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T80aWm10LFaB",
        "outputId": "a719a504-b150-4e82-e44b-2c44a3022432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------+\n",
            "|Stage_by_age|avg(Age)|\n",
            "+------------+--------+\n",
            "|       Adult|   30.25|\n",
            "|    Teenager|    16.0|\n",
            "|       Child|     4.0|\n",
            "+------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, round\n",
        "\n",
        "# Finding the average\n",
        "avg_df = df1.groupBy(\"Stage_by_age\").avg()\n",
        "\n",
        "# Rounding Off\n",
        "for column in avg_df.columns:\n",
        "  if column != \"Stage_by_age\":\n",
        "    avg_df = avg_df.withColumn(column, round(col(column)).cast(\"int\"))\n",
        "\n",
        "avg_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHPe4AbrNEsW",
        "outputId": "1afd074b-5ae2-496b-aded-8c4287191ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------+\n",
            "|Stage_by_age|avg(Age)|\n",
            "+------------+--------+\n",
            "|       Adult|      30|\n",
            "|    Teenager|      16|\n",
            "|       Child|       4|\n",
            "+------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading from csv file\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Practice for importing data\").getOrCreate()\n",
        "\n",
        "mark_df = spark.read.csv(\"/content/drive/MyDrive/Marks_data.csv\")\n",
        "print(mark_df)\n",
        "mark_df.show()\n",
        "mark_df.printSchema()\n",
        "print(type(mark_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn-Jt7Gmy-SO",
        "outputId": "8bac755e-7df2-4c42-e2b2-4736c3270eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string]\n",
            "+----+--------+--------+---+\n",
            "| _c0|     _c1|     _c2|_c3|\n",
            "+----+--------+--------+---+\n",
            "|Name|M1 Score|M2 Score|age|\n",
            "|Alex|      62|      80| 20|\n",
            "|Brad|      45|      56| 19|\n",
            "|Joey|      85|      98| 21|\n",
            "|NULL|      54|      79| 20|\n",
            "|abhi|    NULL|    NULL| 20|\n",
            "+----+--------+--------+---+\n",
            "\n",
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- _c1: string (nullable = true)\n",
            " |-- _c2: string (nullable = true)\n",
            " |-- _c3: string (nullable = true)\n",
            "\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading data\n",
        "mark_df1 = spark.read.csv(\"/content/drive/MyDrive/Marks_data.csv\", header = True, inferSchema= True)\n",
        "mark_df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I5Fnl8Z0Ojx",
        "outputId": "c2ca2462-fa56-4daf-ed0d-83c81761aca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+--------+---+\n",
            "|Name|M1 Score|M2 Score|age|\n",
            "+----+--------+--------+---+\n",
            "|Alex|      62|      80| 20|\n",
            "|Brad|      45|      56| 19|\n",
            "|Joey|      85|      98| 21|\n",
            "|NULL|      54|      79| 20|\n",
            "|abhi|    NULL|    NULL| 20|\n",
            "+----+--------+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering Function\n",
        "mark_df1.filter(mark_df1[\"M1 Score\"] > 60).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPht_Pr7H7RU",
        "outputId": "4522552f-0b84-4732-d4b5-0b57aed4486e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+--------+---+\n",
            "|Name|M1 Score|M2 Score|age|\n",
            "+----+--------+--------+---+\n",
            "|Alex|      62|      80| 20|\n",
            "|Joey|      85|      98| 21|\n",
            "+----+--------+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Average Function\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "mark_df1.select(avg(\"M1 Score\").alias(\"AVG_M1\"), avg(\"M2 Score\").alias(\"AVG_M2\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFJTqFSIJhF7",
        "outputId": "6a89fbb5-9ac0-4b16-bacf-8a22f6115cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+\n",
            "|AVG_M1|AVG_M2|\n",
            "+------+------+\n",
            "|  61.5| 78.25|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Revealing the first few columns of the data\n",
        "mark_df1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Adxu70590ncX",
        "outputId": "6c09c197-5b89-46f6-8286-3cbda95d89ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(Name='Alex', M1 Score=62, M2 Score=80, age=20)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Revealing the columns in the data\n",
        "mark_df1.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBBoEHsm0qIT",
        "outputId": "b028b338-9815-4141-8fb5-e6a5ebccb7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'M1 Score', 'M2 Score', 'age']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Dataframe\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Practice for importing text\").getOrCreate()\n",
        "text_df = spark.read.text(\"/content/drive/MyDrive/practice.txt\")\n",
        "print(type(text_df))\n",
        "text_df.show(truncate = False)\n",
        "text_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBVZhsnO1h-I",
        "outputId": "a302ba05-b10b-40b5-bd57-dc53ebd42ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "+----------------------------------------------------------------+\n",
            "|value                                                           |\n",
            "+----------------------------------------------------------------+\n",
            "|Hey! I am Swathi Baskaran.                                      |\n",
            "|I am currently part of a Data Engineering training at Hexaware. |\n",
            "+----------------------------------------------------------------+\n",
            "\n",
            "root\n",
            " |-- value: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Json dataframe\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Practice for importing json\").getOrCreate()\n",
        "json_df = spark.read.json(\"/content/drive/MyDrive/practice.json\")\n",
        "print(type(json_df))\n",
        "json_df.show(truncate = False)\n",
        "json_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPokmkFn2Za0",
        "outputId": "f7ba0c89-81d3-4187-c8f1-45d8a277913d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "+---+--------------+-------------+\n",
            "|id |product_name  |product_price|\n",
            "+---+--------------+-------------+\n",
            "|1  |Pencil        |5            |\n",
            "|2  |Ball Pen      |10           |\n",
            "|3  |Eraser        |5            |\n",
            "|4  |Parker Ink Pen|50           |\n",
            "+---+--------------+-------------+\n",
            "\n",
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- product_name: string (nullable = true)\n",
            " |-- product_price: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to Pandas\n",
        "files = ['/content/drive/MyDrive/salary.csv', '/content/drive/MyDrive/orders (1).csv']\n",
        "df = spark.read.csv(files, sep = ',', inferSchema = True, header = True)\n",
        "pandasdf = df.toPandas()\n",
        "print(type(pandasdf))\n",
        "print(type(df))\n",
        "print(pandasdf.head())\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mHkEy-zszdA",
        "outputId": "597dbd54-07b4-47a7-fa9c-8ec75a820d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "  cust_id cust_fname cust_lname cust_order cust_status\n",
            "0       1       john        doe          5      active\n",
            "1       2       jane      smith          8      active\n",
            "2       3    micheal    jhonson          3    inactive\n",
            "3       4       abhi    wiliams          1      active\n",
            "4       5        ram      brown          4    inactive\n",
            "+-------+----------+----------+----------+-----------+\n",
            "|cust_id|cust_fname|cust_lname|cust_order|cust_status|\n",
            "+-------+----------+----------+----------+-----------+\n",
            "|      1|      john|       doe|         5|     active|\n",
            "|      2|      jane|     smith|         8|     active|\n",
            "|      3|   micheal|   jhonson|         3|   inactive|\n",
            "|      4|      abhi|   wiliams|         1|     active|\n",
            "|      5|       ram|     brown|         4|   inactive|\n",
            "+-------+----------+----------+----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Lit\n",
        "import pyspark\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('sparkdf').getOrCreate()\n",
        "\n",
        "data = [[\"1\", \"sravan\", \"company 1\"],\n",
        "[\"2\", \"ojaswi\", \"company 1\"],\n",
        "[\"3\", \"rohith\", \"company 2\"],\n",
        "[\"4\", \"sridevi\", \"company 1\"],\n",
        "[\"5\", \"bobby\", \"company 1\"]]\n",
        "\n",
        "columns = ['ID', 'NAME', 'Company']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "df.withColumn(\"salary\",lit(30000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu5LCFpeTzdf",
        "outputId": "77ac43f9-6152-481b-9fda-16075b8ece9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+---------+------+\n",
            "| ID|   NAME|  Company|salary|\n",
            "+---+-------+---------+------+\n",
            "|  1| sravan|company 1| 30000|\n",
            "|  2| ojaswi|company 1| 30000|\n",
            "|  3| rohith|company 2| 30000|\n",
            "|  4|sridevi|company 1| 30000|\n",
            "|  5|  bobby|company 1| 30000|\n",
            "+---+-------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Concat\n",
        "from pyspark.sql.functions import concat\n",
        "df.withColumn(\"Name_Company\", concat(df[\"NAME\"], lit(\" - \"), df[\"Company\"])).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1GO0luSUNXx",
        "outputId": "f2367cf4-b116-4743-9f8c-b546e47ea968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+---------+-------------------+\n",
            "| ID|   NAME|  Company|       Name_Company|\n",
            "+---+-------+---------+-------------------+\n",
            "|  1| sravan|company 1| sravan - company 1|\n",
            "|  2| ojaswi|company 1| ojaswi - company 1|\n",
            "|  3| rohith|company 2| rohith - company 2|\n",
            "|  4|sridevi|company 1|sridevi - company 1|\n",
            "|  5|  bobby|company 1|  bobby - company 1|\n",
            "+---+-------+---------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the count\n",
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "count_rdd = sc.parallelize([2,3,4,5,6,7,8,9])\n",
        "print(count_rdd.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV9caC4Gq_Gq",
        "outputId": "6f35eda2-d226-4622-9993-f1019518d54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the first element\n",
        "print(count_rdd.first())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jIEbBJkrOD_",
        "outputId": "2ac7e541-e34a-4583-abfe-c55b7d6728a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking a certain number of elements\n",
        "print(count_rdd.take(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbyZaH5Lrc4O",
        "outputId": "177e154d-3b93-407d-97c2-c8ea90e4e64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce - Takes 2 elements from the given RDD and operates\n",
        "reduce_rdd = sc.parallelize([1,2,6,8,3])\n",
        "print(reduce_rdd.reduce(lambda x,y: x*y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLjzW7HfriB1",
        "outputId": "833d008a-e844-46d0-d815-b695803292f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving as Text file\n",
        "count_rdd.saveAsTextFile(\"numbers.txt\")"
      ],
      "metadata": {
        "id": "OIQ-vnP6srq4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}